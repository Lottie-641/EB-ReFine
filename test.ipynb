{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c8c147-a9ab-4869-a5ae-d11eb102d3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from jellyfish import damerau_levenshtein_distance\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "from neural_network.llamp_multiout import BertMultiOutputClassificationHeads\n",
    "from preprocessing.log_to_history import Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b887f0-a97d-43d3-93a8-1058ea36f3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device -> cuda\n"
     ]
    }
   ],
   "source": [
    "csv_log = \"helpdesk\"   # e.g. helpdesk, sepsis, bpic2017_o, bpic2020 ...\n",
    "TYPE = \"all\"\n",
    "\n",
    "semantic_dir = \"semantic_data\"\n",
    "models_dir = \"models\"\n",
    "model_name = \"prajjwal1/bert-medium\"\n",
    "MAX_LEN = 512\n",
    "\n",
    "beta = 0.8\n",
    "threshold = 0.4\n",
    "\n",
    "N_RUNS = 2000\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device ->\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609e1b25-2a77-4eb8-9a5d-9b87a0482107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path: str):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def clean_sequence(sequence_str, label2id):\n",
    "    sequence_list = sequence_str.split(\" \")\n",
    "    end_activity_str = str(label2id[\"activity\"][\"ENDactivity\"])\n",
    "    if end_activity_str in sequence_list:\n",
    "        first_end_index = sequence_list.index(end_activity_str)\n",
    "        sequence_list = sequence_list[: first_end_index + 1]\n",
    "    return \" \".join(sequence_list)\n",
    "\n",
    "def pad_list_to_length(seq, target_length, end_id):\n",
    "    if target_length <= 0:\n",
    "        return seq\n",
    "    if len(seq) == 0:\n",
    "        return [0] * target_length\n",
    "    if len(seq) < target_length:\n",
    "        return seq + [end_id] * (target_length - len(seq))\n",
    "    if len(seq) > target_length:\n",
    "        return seq[:target_length]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "332e20ff-fc51-4639-ba8a-0f10319230db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_suffix_no_freq(model_output):\n",
    "    predicted = []\n",
    "    for i in range(len(model_output)):\n",
    "        pred = model_output[i].argmax(dim=1).cpu().numpy()\n",
    "        predicted.append(str(pred[0]))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8b6d21-7c92-44fe-8cfc-fb07ef6ebb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_suffix_with_freq(model_output, prefix_sequence, trace_frequencies, label2id, beta, threshold):\n",
    "    # fixed padding length from db\n",
    "    if len(trace_frequencies) == 0:\n",
    "        max_len_in_db = 0\n",
    "    else:\n",
    "        max_len_in_db = max(len(k) for k in trace_frequencies.keys())\n",
    "\n",
    "    end_id = label2id[\"activity\"][\"ENDactivity\"]\n",
    "\n",
    "    # 1) model suffix\n",
    "    model_suffix_full = predict_suffix_no_freq(model_output)          \n",
    "    model_suffix_cut = clean_sequence(\" \".join(model_suffix_full), label2id).split()\n",
    "    \n",
    "    if len(model_suffix_cut) > 0 and model_suffix_cut[-1] == str(end_id):\n",
    "        model_suffix = model_suffix_cut[:-1]\n",
    "    else:\n",
    "        model_suffix = model_suffix_cut\n",
    "\n",
    "    prefix_ints = [int(x) for x in prefix_sequence]\n",
    "    suffix_ints = [int(x) for x in model_suffix]\n",
    "    candidate_trace = prefix_ints + suffix_ints\n",
    "\n",
    "    # 2) pad candidate before exact match\n",
    "    padded_candidate = pad_list_to_length(candidate_trace, max_len_in_db, end_id)\n",
    "    candidate_tuple = tuple(padded_candidate)\n",
    "\n",
    "    # 3) exact match\n",
    "    if candidate_tuple in trace_frequencies:\n",
    "        return model_suffix\n",
    "\n",
    "    # 4) best match\n",
    "    if len(trace_frequencies) == 0 or max_len_in_db == 0:\n",
    "        return model_suffix\n",
    "\n",
    "    best_trace = None\n",
    "    best_similarity = -1.0\n",
    "    best_freq = -1.0\n",
    "    best_tau = -1.0\n",
    "\n",
    "    candidate_str = \" \".join(map(str, padded_candidate))\n",
    "    f_max = max(trace_frequencies.values())\n",
    "\n",
    "    for hist_trace, freq in trace_frequencies.items():\n",
    "        hist_list = list(hist_trace)\n",
    "        padded_hist = pad_list_to_length(hist_list, max_len_in_db, end_id)\n",
    "        hist_str = \" \".join(map(str, padded_hist))\n",
    "\n",
    "        dl_dist = damerau_levenshtein_distance(candidate_str, hist_str)\n",
    "        similarity = max(0.0, 1.0 - (dl_dist / max_len_in_db))\n",
    "        tau = beta * similarity + (1.0 - beta) * (freq / f_max)\n",
    "\n",
    "        if (\n",
    "            tau > best_tau\n",
    "            or (tau == best_tau and similarity > best_similarity)\n",
    "            or (tau == best_tau and similarity == best_similarity and freq > best_freq)\n",
    "        ):\n",
    "            best_tau = tau\n",
    "            best_similarity = similarity\n",
    "            best_freq = freq\n",
    "            best_trace = hist_list\n",
    "\n",
    "    if best_similarity >= threshold and best_trace is not None and len(best_trace) > len(prefix_ints):\n",
    "        override_suffix_int = best_trace[len(prefix_ints):]\n",
    "        return list(map(str, override_suffix_int))\n",
    "\n",
    "    return model_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18ddbf1-7d76-4e2d-bba8-282b07981dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_labels(id_list, id2label):\n",
    "    out = []\n",
    "    for x in id_list:\n",
    "        try:\n",
    "            out.append(id2label[\"activity\"][int(x)])\n",
    "        except Exception:\n",
    "            out.append(str(x))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d857ed35-7fd0-47b9-8118-88c5cf24167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync():\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce1ffff-bcc9-4002-b7c6-9eecfe0349c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_prefix(prefix_str: str, prefix_mode: str, label2id: dict):\n",
    "    \"\"\"\n",
    "    prefix_mode=\"id\"   : prefix_str is space-separated IDs (e.g., \"12 5 9\")\n",
    "    prefix_mode=\"name\" : prefix_str is space-separated activity names (each name must NOT contain spaces)\n",
    "                         (e.g., \"CreateTicket AssignTicket ENDactivity\")\n",
    "    Returns:\n",
    "      prefix_sequence (list[str])      : IDs as strings\n",
    "      prefix_text_for_tokenizer (str)  : space-separated IDs (text fed into tokenizer)\n",
    "    \"\"\"\n",
    "    tokens = [t for t in prefix_str.strip().split() if t != \"\"]\n",
    "    if len(tokens) == 0:\n",
    "        raise ValueError(\"prefix_str is empty\")\n",
    "\n",
    "    if prefix_mode == \"id\":\n",
    "        return tokens, \" \".join(tokens)\n",
    "\n",
    "    if prefix_mode == \"name\":\n",
    "        ids = []\n",
    "        for name in tokens:\n",
    "            if name not in label2id[\"activity\"]:\n",
    "                raise KeyError(f\"Unknown activity name: {name}\")\n",
    "            ids.append(str(label2id[\"activity\"][name]))\n",
    "        return ids, \" \".join(ids)\n",
    "\n",
    "    raise ValueError('prefix_mode must be \"id\" or \"name\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5084eea-ecfe-4af1-9f2d-66f0c0ef7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Log(csv_log, TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbcecbc-a52e-43d8-bb9b-a93b2db40cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: models/helpdesk_all.pth\n",
      "#heads: 15  classes/head: 15\n"
     ]
    }
   ],
   "source": [
    "base = os.path.join(semantic_dir, csv_log)\n",
    "id2label = load_pickle(os.path.join(base, f\"{csv_log}_id2label_{TYPE}.pkl\"))\n",
    "label2id = load_pickle(os.path.join(base, f\"{csv_log}_label2id_{TYPE}.pkl\"))\n",
    "\n",
    "y_train_suffix = load_pickle(os.path.join(base, f\"{csv_log}_suffix_train_{TYPE}.pkl\"))\n",
    "trace_frequencies = load_pickle(os.path.join(base, f\"{csv_log}_encoded_trace_frequencies_{TYPE}.pkl\"))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side=\"left\")\n",
    "backbone = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "output_sizes = [len(id2label[\"activity\"]) for _ in range(len(y_train_suffix))]\n",
    "model = BertMultiOutputClassificationHeads(backbone, output_sizes)\n",
    "\n",
    "model_path = os.path.join(models_dir, f\"{csv_log}_{TYPE}.pth\")\n",
    "state = torch.load(model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(state)\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded model:\", model_path)\n",
    "print(\"#heads:\", len(output_sizes), \" classes/head:\", output_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66437e4a-bf7b-4ec8-a6d6-9599f0eb41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Input prefix here (two modes)\n",
    "# mode=\"id\":    prefix_str = \"12 5 9\"\n",
    "# mode=\"name\":  prefix_str = \"Create Ticket Assign Ticket ENDactivity\"\n",
    "# =====================\n",
    "prefix_str = \"0 2\" #Assignseriousness Takeinchargeticket Wait         \n",
    "prefix_mode = \"id\"       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae5875a-0b33-4229-8b72-6001839d0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_sequence, prefix_text_for_tokenizer = parse_prefix(prefix_str, prefix_mode, label2id)\n",
    "\n",
    "enc = tokenizer(\n",
    "    prefix_text_for_tokenizer,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "input_ids = enc[\"input_ids\"].to(device)\n",
    "attention_mask = enc[\"attention_mask\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99dde699-cb1e-4882-b05d-0cd89f1e3a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prefix IDs        : ['0', '2']\n",
      "No-freq Suffix IDs: ['1', '2', '3', '14']\n",
      "Freq   Suffix IDs : ['1', '2', '3']\n",
      "\n",
      "No-freq labels: ['Takeinchargeticket', 'Resolveticket', 'Closed', 'ENDactivity']\n",
      "Freq   labels: ['Takeinchargeticket', 'Resolveticket', 'Closed']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "\n",
    "pred_no = predict_suffix_no_freq(outputs)\n",
    "pred_no = clean_sequence(\" \".join(pred_no), label2id).split()\n",
    "\n",
    "pred_w = predict_suffix_with_freq(\n",
    "    outputs,\n",
    "    prefix_sequence,\n",
    "    trace_frequencies,\n",
    "    label2id,\n",
    "    beta=beta,\n",
    "    threshold=threshold,\n",
    ")\n",
    "pred_w = clean_sequence(\" \".join(pred_w), label2id).split()\n",
    "\n",
    "print(\"\\nPrefix IDs        :\", prefix_sequence)\n",
    "print(\"No-freq Suffix IDs:\", pred_no)\n",
    "print(\"Freq   Suffix IDs :\", pred_w)\n",
    "\n",
    "print(\"\\nNo-freq labels:\", ids_to_labels(pred_no, id2label))\n",
    "print(\"Freq   labels:\", ids_to_labels(pred_w, id2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9e988bf-8a3d-467e-9a5e-a070d4c71e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference time comparison 2000 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be1516ed-f57e-489e-8b0a-b7555b7ad2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Timing Report ==========\n",
      "No-freq   total: 6.410728s   avg/run: 0.003205s\n",
      "With-freq total: 6.447285s   avg/run: 0.003224s\n"
     ]
    }
   ],
   "source": [
    "def run_no_freq():\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids, attention_mask)\n",
    "    pred = predict_suffix_no_freq(out)\n",
    "    pred = clean_sequence(\" \".join(pred), label2id).split()\n",
    "    return pred\n",
    "\n",
    "def run_with_freq():\n",
    "    with torch.no_grad():\n",
    "        out = model(input_ids, attention_mask)\n",
    "    pred = predict_suffix_with_freq(out, prefix_sequence, trace_frequencies, label2id, beta=beta, threshold=threshold)\n",
    "    pred = clean_sequence(\" \".join(pred), label2id).split()\n",
    "    return pred\n",
    "\n",
    "# warmup (GPU timing更稳)\n",
    "for _ in range(10):\n",
    "    _ = run_no_freq()\n",
    "    _ = run_with_freq()\n",
    "\n",
    "# no-freq timing\n",
    "sync()\n",
    "t0 = time.perf_counter()\n",
    "for _ in range(N_RUNS):\n",
    "    _ = run_no_freq()\n",
    "sync()\n",
    "t1 = time.perf_counter()\n",
    "total_no = t1 - t0\n",
    "\n",
    "# with-freq timing\n",
    "sync()\n",
    "t2 = time.perf_counter()\n",
    "for _ in range(N_RUNS):\n",
    "    _ = run_with_freq()\n",
    "sync()\n",
    "t3 = time.perf_counter()\n",
    "total_w = t3 - t2\n",
    "\n",
    "print(\"\\n========== Timing Report ==========\")\n",
    "print(f\"No-freq   total: {total_no:.6f}s   avg/run: {total_no/N_RUNS:.6f}s\")\n",
    "print(f\"With-freq total: {total_w:.6f}s   avg/run: {total_w/N_RUNS:.6f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aadb49-67bd-4435-a685-2a53824ef5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
