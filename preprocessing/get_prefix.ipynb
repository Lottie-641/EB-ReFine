{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3015e402-ddef-4cdc-9e6e-47bdd6d81264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import log_config as lg\n",
    "from jinja2 import Template\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from itertools import chain, repeat, islice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57897fc-53df-4cda-bcce-3a28242cfad0",
   "metadata": {},
   "source": [
    "Load & Preprocess Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87114f0c-1efc-4dd3-9180-6235ac6e1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name = \"helpdesk\"  \n",
    "log = pd.read_csv(f'../event_log/{log_name}.csv')\n",
    "\n",
    "# Clean up column names\n",
    "log['activity'] = log['activity'].str.replace(' ', '').str.replace('+', '').str.replace('-', '').str.replace('_', '')\n",
    "\n",
    "if log_name != 'sepsis':\n",
    "    log['resource'] = log['resource'].astype(str).str.replace(' ', '').str.replace('+', '').str.replace('-', '').str.replace('_', '')\n",
    "\n",
    "log.fillna('UNK', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00aa447b-81e6-46be-afa9-881a608b7034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     case            activity resource                timestamp customer  \\\n",
      "0  Case 1   Assignseriousness   Value1  2012/10/09 14:50:17.000  Value 1   \n",
      "1  Case 1  Takeinchargeticket   Value1  2012/10/09 14:51:01.000  Value 1   \n",
      "2  Case 1  Takeinchargeticket   Value2  2012/10/12 15:02:56.000  Value 1   \n",
      "3  Case 1       Resolveticket   Value1  2012/10/25 11:54:26.000  Value 1   \n",
      "4  Case 1              Closed   Value3  2012/11/09 12:54:39.000  Value 1   \n",
      "\n",
      "   product responsiblesection seriousness2 servicelevel servicetype  \\\n",
      "0  Value 1            Value 1      Value 1      Value 1     Value 1   \n",
      "1  Value 1            Value 1      Value 1      Value 1     Value 1   \n",
      "2  Value 1            Value 1      Value 1      Value 2     Value 1   \n",
      "3  Value 1            Value 1      Value 1      Value 2     Value 1   \n",
      "4  Value 1            Value 1      Value 1      Value 2     Value 1   \n",
      "\n",
      "  supportsection workgroup  \n",
      "0        Value 1   Value 1  \n",
      "1        Value 1   Value 1  \n",
      "2        Value 1   Value 1  \n",
      "3        Value 1   Value 1  \n",
      "4        Value 1   Value 1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21348 entries, 0 to 21347\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   case                21348 non-null  object\n",
      " 1   activity            21348 non-null  object\n",
      " 2   resource            21348 non-null  object\n",
      " 3   timestamp           21348 non-null  object\n",
      " 4   customer            21348 non-null  object\n",
      " 5   product             21348 non-null  object\n",
      " 6   responsiblesection  21348 non-null  object\n",
      " 7   seriousness2        21348 non-null  object\n",
      " 8   servicelevel        21348 non-null  object\n",
      " 9   servicetype         21348 non-null  object\n",
      " 10  supportsection      21348 non-null  object\n",
      " 11  workgroup           21348 non-null  object\n",
      "dtypes: object(12)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(log.head())\n",
    "print(log.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9133a2-eac6-4230-8caa-845d84187443",
   "metadata": {},
   "source": [
    "Compute Timestamp Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399605bc-5e0f-4e34-ae12-46f14913fe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4125106/233166892.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  log = log.groupby('case', group_keys=False).apply(extract_timestamp_features)\n"
     ]
    }
   ],
   "source": [
    "def extract_timestamp_features(group):\n",
    "    timestamp_col = 'timestamp'\n",
    "    group = group.sort_values(timestamp_col, ascending=True)\n",
    "    start_date = group[timestamp_col].iloc[0]\n",
    "\n",
    "    group[\"timesincelastevent\"] = group[timestamp_col].diff().fillna(pd.Timedelta(seconds=0))\n",
    "    group[\"timesincelastevent\"] = group[\"timesincelastevent\"].apply(lambda x: float(x / np.timedelta64(1, 's')))\n",
    "\n",
    "    group[\"timesincecasestart\"] = (group[timestamp_col] - start_date).fillna(pd.Timedelta(seconds=0))\n",
    "    group[\"timesincecasestart\"] = group[\"timesincecasestart\"].apply(lambda x: float(x / np.timedelta64(1, 's')))\n",
    "\n",
    "    return group\n",
    "\n",
    "log['timestamp'] = pd.to_datetime(log['timestamp'])\n",
    "log = log.groupby('case', group_keys=False).apply(extract_timestamp_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df69222-3840-4ed6-a986-c4ae5a84b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     case            activity resource           timestamp customer  product  \\\n",
      "0  Case 1   Assignseriousness   Value1 2012-10-09 14:50:17  Value 1  Value 1   \n",
      "1  Case 1  Takeinchargeticket   Value1 2012-10-09 14:51:01  Value 1  Value 1   \n",
      "2  Case 1  Takeinchargeticket   Value2 2012-10-12 15:02:56  Value 1  Value 1   \n",
      "3  Case 1       Resolveticket   Value1 2012-10-25 11:54:26  Value 1  Value 1   \n",
      "4  Case 1              Closed   Value3 2012-11-09 12:54:39  Value 1  Value 1   \n",
      "\n",
      "  responsiblesection seriousness2 servicelevel servicetype supportsection  \\\n",
      "0            Value 1      Value 1      Value 1     Value 1        Value 1   \n",
      "1            Value 1      Value 1      Value 1     Value 1        Value 1   \n",
      "2            Value 1      Value 1      Value 2     Value 1        Value 1   \n",
      "3            Value 1      Value 1      Value 2     Value 1        Value 1   \n",
      "4            Value 1      Value 1      Value 2     Value 1        Value 1   \n",
      "\n",
      "  workgroup  timesincelastevent  timesincecasestart  \n",
      "0   Value 1                 0.0                 0.0  \n",
      "1   Value 1                44.0                44.0  \n",
      "2   Value 1            259915.0            259959.0  \n",
      "3   Value 1           1111890.0           1371849.0  \n",
      "4   Value 1           1299613.0           2671462.0  \n"
     ]
    }
   ],
   "source": [
    "print(log.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fef2c4-93c9-49b6-9fab-fb99eb7219e5",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3a8e5a-2b6f-4c5d-a16c-1e1e948ecf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 14193\n",
      "Test Size: 7155\n"
     ]
    }
   ],
   "source": [
    "grouped = log.groupby(\"case\")\n",
    "start_timestamps = grouped[\"timestamp\"].min().reset_index()\n",
    "start_timestamps = start_timestamps.sort_values(\"timestamp\", ascending=True, kind=\"mergesort\")\n",
    "\n",
    "train_ids = list(start_timestamps[\"case\"])[:int(0.66 * len(start_timestamps))]\n",
    "train = log[log[\"case\"].isin(train_ids)].sort_values(\"timestamp\", ascending=True, kind='mergesort')\n",
    "test = log[~log[\"case\"].isin(train_ids)].sort_values(\"timestamp\", ascending=True, kind='mergesort')\n",
    "\n",
    "print(\"Train Size:\", len(train))\n",
    "print(\"Test Size:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecef744-a57c-4871-82c4-6639bc05dfb6",
   "metadata": {},
   "source": [
    "Generate Prefix Histories //\n",
    "history_train----train  //\n",
    "len_prefix_train----len_train //\n",
    "dict_suffix_train----suffix_train //\n",
    "_dict_label_train[lg.log[__log_name]['target']----label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8259a4b-1eb7-4006-8ea2-3530e817a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_infinite(iterable, padding=None):\n",
    "    return chain(iterable, repeat(padding))\n",
    "\n",
    "def pad(iterable, size, padding=None):\n",
    "    return islice(pad_infinite(iterable, padding), size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1408db2-e09d-4947-ae6d-9c7fd4958cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating prefix history...\n",
      "Generating prefix history...\n"
     ]
    }
   ],
   "source": [
    "def gen_prefix_history(df, log_name):\n",
    "    print('Generating prefix history...')\n",
    "    list_seq = []\n",
    "    list_len_prefix = []\n",
    "    sequence = df.groupby('case', sort=False)\n",
    "\n",
    "    event_template = Template(lg.log[log_name]['event_template'])\n",
    "    trace_template = Template(lg.log[log_name]['trace_template'])\n",
    "\n",
    "    dict_event_label = {v: [] for v in lg.log[log_name]['event_attribute']}\n",
    "    dict_trace_label = {v: [] for v in lg.log[log_name]['trace_attribute']}\n",
    "    dict_len_label = {i: [] for i in range(max(df['case'].value_counts()))}\n",
    "\n",
    "    for group_name, group_data in sequence:\n",
    "        event_dict_hist = {}\n",
    "        trace_dict_hist = {}\n",
    "        event_text = ''\n",
    "        len_prefix = 1\n",
    "        activity_list = []\n",
    "\n",
    "        for index, row in group_data.iterrows():\n",
    "            activity_list.append(row['activity'])\n",
    "            for v in lg.log[log_name]['event_attribute']:\n",
    "                value = row[v]\n",
    "                event_dict_hist[v] = value.replace(' ', '') if isinstance(value, str) else value\n",
    "            event_text += event_template.render(event_dict_hist) + ' '\n",
    "\n",
    "            for w in lg.log[log_name]['trace_attribute']:\n",
    "                value = row[w]\n",
    "                trace_dict_hist[w] = value.replace(' ', '') if isinstance(value, str) else value\n",
    "            trace_text = trace_template.render(trace_dict_hist)\n",
    "\n",
    "            prefix_hist = event_text + trace_text\n",
    "            list_seq.append(prefix_hist)\n",
    "            list_len_prefix.append(len_prefix)\n",
    "            len_prefix += 1\n",
    "\n",
    "        suffixes = []\n",
    "        activity_list.pop(0)\n",
    "        activity_list.append('ENDactivity')\n",
    "\n",
    "        for i in range(len(activity_list)):\n",
    "            suffixes.append(list(pad(activity_list[i:], max(df['case'].value_counts()), 'ENDactivity')))\n",
    "        for s in suffixes:\n",
    "            for i in range(len(s)):\n",
    "                dict_len_label[i].append(s[i])\n",
    "\n",
    "    return list_seq, dict_event_label, list_len_prefix, dict_len_label\n",
    "\n",
    "history_train, dict_label_train, len_prefix_train, dict_suffix_train = gen_prefix_history(train, log_name)\n",
    "history_test, dict_label_test, len_prefix_test, dict_suffix_test = gen_prefix_history(test, log_name)\n",
    "for v in dict_label_train:\n",
    "    if v!='timesincecasestart':\n",
    "        temp_list = []\n",
    "        for key in dict_label_train[v]:\n",
    "                temp_list.append(label2id[v].get(key))\n",
    "        dict_label_train[v] = torch.tensor(temp_list)\n",
    "    else:\n",
    "        dict_label_train[v] = torch.tensor(dict_label_train[v]).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f0416bd-546d-4c39-8dae-d05263acdb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three history_train values:\n",
      "History 1: Value2 performed Assignseriousness 0.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Section Value4 led by Value5\n",
      "History 2: Value2 performed Assignseriousness 0.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Value2 performed Takeinchargeticket 1383122.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Section Value4 led by Value5\n",
      "History 3: Value2 performed Assignseriousness 0.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Value2 performed Takeinchargeticket 1383122.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Value2 performed Resolveticket 1383129.0 seconds ago from the beginning of the trace. Value3 managed the request for the Value3 of Value63 with service Value1 of level Value2. Section Value4 led by Value5\n",
      "\n",
      "==================================================\n",
      "\n",
      "First three len_prefix_train values:\n",
      "[1, 2, 3]\n",
      "\n",
      "==================================================\n",
      "\n",
      "First three values for target 'activity':\n",
      "tensor([])\n",
      "First three values in dict_suffix_train for each index:\n",
      "Index 0: ['Takeinchargeticket', 'Resolveticket', 'Closed']\n",
      "Index 1: ['Resolveticket', 'Closed', 'Closed']\n",
      "Index 2: ['Closed', 'Closed', 'ENDactivity']\n",
      "Index 3: ['Closed', 'ENDactivity', 'ENDactivity']\n",
      "Index 4: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 5: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 6: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 7: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 8: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 9: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 10: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 11: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 12: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 13: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n",
      "Index 14: ['ENDactivity', 'ENDactivity', 'ENDactivity']\n"
     ]
    }
   ],
   "source": [
    "# Print the first three history strings\n",
    "print(\"First three history_train values:\")\n",
    "for i, hist in enumerate(history_train[:3]):\n",
    "    print(f\"History {i+1}: {hist}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Print the first three prefix lengths\n",
    "print(\"First three len_prefix_train values:\")\n",
    "print(len_prefix_train[:3])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Print the first three entries for each key in dict_label_train\n",
    "target_key = lg.log[log_name]['target']\n",
    "print(f\"First three values for target '{target_key}':\")\n",
    "print(dict_label_train[lg.log[log_name]['target']][:3])\n",
    "\n",
    "\n",
    "# Print the first three entries for each key in dict_suffix_train\n",
    "print(\"First three values in dict_suffix_train for each index:\")\n",
    "for key, values in dict_suffix_train.items():\n",
    "    print(f\"Index {key}: {values[:3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6488a1-3a42-4459-9f6a-788c1b9af6fd",
   "metadata": {},
   "source": [
    "Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db4aa92-5963-4810-8139-6132b42c2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_object(obj, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "serialize_object(history_train, 'history_train.pkl')\n",
    "serialize_object(history_test, 'history_test.pkl')\n",
    "serialize_object(len_prefix_train, 'len_prefix_train.pkl')\n",
    "serialize_object(len_prefix_test, 'len_prefix_test.pkl')\n",
    "serialize_object(dict_suffix_train, 'suffix_train.pkl')\n",
    "serialize_object(dict_suffix_test, 'suffix_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab39d4-1791-42d7-9475-30bb2968d272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
