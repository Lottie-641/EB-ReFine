{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0c38b1-8f8a-43c7-b95e-bb0f520cd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b175827-a76f-4905-92d1-e9b9a347b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3597d0-2efb-418c-9b60-b6b6cb6d64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored traces\n",
    "def load_traces(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        distinct_traces = pickle.load(f)\n",
    "    return distinct_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a35dfe-c97d-4269-baff-f851ee6ad892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded traces: [((0, 7, 5, 3, 24, 0, 8, 5, 0, 7, 5, 0, 25, 9, 7, 8, 10, 5, 5, 12, 0, 17, 5, 12, 27, 7, 5, 10, 0, 4, 5, 5, 35, 8, 1, 6, 13, 14, 5, 0, 4, 7, 3, 24, 26, 5, 33, 5, 11, 10, 5, 12, 13, 14, 13, 5, 14, 15, 16, 0, 19, 5, 20, 21, 5, 0, 30, 26, 4, 5, 27, 12, 5, 34, 24, 2, 3, 0, 26, 17, 18, 9, 7, 10, 19, 20, 5, 31, 19, 5, 20, 5, 5, 21, 23), 0.191516813160229), ((0, 17, 5, 0, 25, 5, 12, 5, 7, 26, 4, 5, 0, 25, 28, 5, 7, 10, 0, 7, 5, 4, 26, 5, 0, 10, 1, 26, 5, 3, 5, 13, 24, 14, 0, 3, 6, 35, 8, 5, 27, 26, 5, 34, 5, 0, 6, 5, 25, 4, 3, 26, 5, 13, 14, 5, 13, 14, 16, 0, 8, 17, 5, 5, 35, 6, 18, 19, 20, 22, 19, 20, 5, 31, 5, 0, 25, 5, 27, 7, 10, 5, 0, 8, 5, 12, 1, 3, 7, 5, 19, 20, 5, 31, 23), 0.191516813160229), ((0, 1, 0, 4, 5, 1, 5, 0, 3, 8, 6, 5, 5, 27, 1, 34, 5, 0, 6, 0, 1, 17, 5, 9, 10, 12, 5, 0, 4, 5, 35, 8, 12, 7, 1, 25, 28, 35, 6, 5, 13, 5, 14, 0, 5, 35, 6, 7, 13, 10, 12, 14, 5, 16, 0, 17, 12, 5, 7, 24, 5, 3, 10, 0, 1, 5, 8, 19, 35, 6, 5, 20, 21, 0, 5, 26, 5, 7, 27, 9, 10, 12, 0, 1, 9, 7, 10, 12, 19, 5, 20, 22, 5, 23, 36), 0.1895008467059108), ((0, 11, 0, 5, 0, 17, 27, 32, 34, 5, 7, 5, 10, 0, 1, 26, 33, 11, 5, 5, 6, 8, 5, 0, 10, 5, 6, 13, 8, 14, 5, 15, 0, 5, 7, 5, 32, 33, 11, 4, 26, 0, 12, 10, 5, 4, 26, 25, 3, 24, 7, 8, 5, 13, 5, 5, 14, 13, 14, 15, 16, 0, 0, 8, 0, 7, 28, 5, 25, 6, 8, 1, 3, 5, 19, 5, 20, 21, 0, 17, 7, 19, 5, 10, 5, 20, 22, 19, 20, 5, 22, 23, 36, 36, 36), 0.18546891379727443), ((0, 5, 4, 12, 7, 10, 5, 0, 4, 35, 8, 5, 5, 35, 6, 9, 7, 10, 12, 5, 0, 25, 12, 5, 3, 10, 5, 2, 24, 5, 0, 6, 17, 5, 27, 18, 0, 1, 8, 3, 24, 6, 10, 5, 12, 5, 5, 5, 30, 29, 5, 13, 14, 13, 14, 15, 13, 14, 16, 0, 17, 26, 5, 4, 5, 19, 20, 31, 0, 33, 5, 1, 19, 5, 20, 31, 5, 0, 7, 5, 0, 5, 30, 27, 34, 6, 5, 19, 20, 22, 23, 36, 36, 36, 36), 0.18345294734295622)]\n"
     ]
    }
   ],
   "source": [
    "# Load traces and frequencies\n",
    "data = \"mip\"\n",
    "trace_data = load_traces('../semantic_data/' + data + '/' + data + '_encoded_trace_frequencies_all.pkl')\n",
    "print(\"Loaded traces:\", list(trace_data.items())[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf95af4-5208-4d03-bd72-7a70181f6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensor_to_list(encoded_traces):\n",
    "    formatted_traces = {}\n",
    "    for trace_tensor, freq in encoded_traces.items():\n",
    "        # Ensure trace_tensor is a list if it's not already a tuple\n",
    "        if isinstance(trace_tensor, tuple):\n",
    "            formatted_traces[trace_tensor] = freq\n",
    "        else:\n",
    "            formatted_traces[tuple(trace_tensor.tolist())] = freq  # Convert tensor to tuple (hashable)\n",
    "    return formatted_traces\n",
    "\n",
    "def convert_trace_to_text(formatted_traces):\n",
    "    text_traces = {}\n",
    "    for trace, freq in formatted_traces.items():\n",
    "        text_trace = \" \".join(map(str, trace))  # Convert tuple of numbers to space-separated string\n",
    "        text_traces[text_trace] = freq\n",
    "    return text_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b925c7c3-f618-4648-9323-4603239bba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_traces = convert_tensor_to_list(trace_data)\n",
    "#print(\"Converted Traces:\", formatted_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bd4b7-b0a7-421a-b9f6-f9553538ed3a",
   "metadata": {},
   "source": [
    "**Convert Encoded Traces to Text Format for BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "839c0966-ea96-4dc5-bde2-4d0fee57fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_traces = convert_trace_to_text(formatted_traces)\n",
    "#print(\"Text Traces:\", text_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83246a57-f544-487a-8571-32b58341aa20",
   "metadata": {},
   "source": [
    "**Generate BERT Embeddings for Encoded Traces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b40db6-9ea4-46e9-99b5-d471f54b0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-medium', truncation_side='left')\n",
    "model = AutoModel.from_pretrained('prajjwal1/bert-medium')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def generate_bert_embeddings(text_traces):\n",
    "    \"\"\"\n",
    "    Convert each trace into an embedding using a pretrained BERT model.\n",
    "    \n",
    "    Args:\n",
    "        text_traces (dict): {trace_text: frequency} mapping.\n",
    "\n",
    "    Returns:\n",
    "        dict: {trace_text: (embedding vector, frequency)}\n",
    "    \"\"\"\n",
    "    model.eval()  # Set BERT to evaluation mode\n",
    "    trace_embeddings = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for trace_text, freq in text_traces.items():\n",
    "            # Tokenize the trace sequence\n",
    "            inputs = tokenizer(trace_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}  # Move tensors to GPU if available\n",
    "            \n",
    "            # Get BERT embeddings\n",
    "            outputs = model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # Extract [CLS] token embedding\n",
    "\n",
    "            # Store embedding with frequency\n",
    "            trace_embeddings[trace_text] = (cls_embedding, freq)\n",
    "\n",
    "    return trace_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b17154-e5d2-4237-9e14-1d9d4ad80314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "bert_embeddings = generate_bert_embeddings(text_traces)\n",
    "#print(\"Example Embedding:\", list(bert_embeddings.items())[:1])  # Check format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8979e2b8-26a9-405f-a059-4abc3b7fa8ff",
   "metadata": {},
   "source": [
    "**Store Embeddings for Future Use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "806f70f9-6ba7-4afa-9196-b5aa0e57cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(file_path, embeddings):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62e22234-1249-46c1-b1d9-482e750b31de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved successfully!\n"
     ]
    }
   ],
   "source": [
    "save_embeddings('../semantic_data/' + data + '/trace_embeddings_vd.pkl', bert_embeddings)\n",
    "print(\"Embeddings saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98b454a-83a2-42cc-bdb2-301ef6d627c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "############# Trace emdedding complete ########################\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb2a2f1-817c-4b11-9a59-55307ada0680",
   "metadata": {},
   "source": [
    "**Step 2: Storing BERT Embeddings in FAISS for Fast Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1662d25-3594-46c6-b64d-f8172c2ae27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 trace embeddings\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load saved embeddings\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    return embeddings\n",
    "\n",
    "# Load embeddings\n",
    "bert_embeddings = load_embeddings('../semantic_data/' + data + '/trace_embeddings_vd.pkl')\n",
    "print(\"Loaded\", len(bert_embeddings), \"trace embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0f1106-b238-48b6-bb93-68477df36305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS Index Created (Dimension: 512 )\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def create_faiss_index(embedding_dim):\n",
    "    \"\"\"\n",
    "    Creates a FAISS index for fast similarity search.\n",
    "\n",
    "    Args:\n",
    "        embedding_dim (int): The dimension of the embeddings (BERT: 768).\n",
    "\n",
    "    Returns:\n",
    "        faiss.IndexFlatL2: Initialized FAISS index.\n",
    "    \"\"\"\n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # L2 distance search index\n",
    "    return index\n",
    "\n",
    "# Initialize FAISS index\n",
    "embedding_dim = len(next(iter(bert_embeddings.values()))[0])  # Get embedding size\n",
    "faiss_index = create_faiss_index(embedding_dim)\n",
    "print(\"FAISS Index Created (Dimension:\", embedding_dim, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc2d4bd-9e71-4ddf-9653-5b8ab4ed29cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1000 traces into FAISS\n"
     ]
    }
   ],
   "source": [
    "def insert_embeddings_into_faiss(embeddings, index):\n",
    "    \"\"\"\n",
    "    Inserts embeddings into the FAISS index.\n",
    "\n",
    "    Args:\n",
    "        embeddings (dict): {trace_text: (embedding_vector, frequency)}\n",
    "        index (faiss.Index): FAISS index to store embeddings.\n",
    "\n",
    "    Returns:\n",
    "        list: Mapping of FAISS index positions to trace texts.\n",
    "    \"\"\"\n",
    "    trace_mapping = []\n",
    "    vectors = []\n",
    "\n",
    "    for trace_text, (embedding, freq) in embeddings.items():\n",
    "        trace_mapping.append((trace_text, freq))  # Store original text and frequency\n",
    "        vectors.append(embedding)\n",
    "\n",
    "    vectors = np.array(vectors).astype('float32')\n",
    "    index.add(vectors)  # Insert all embeddings into FAISS\n",
    "\n",
    "    return trace_mapping\n",
    "\n",
    "# Insert embeddings into FAISS\n",
    "trace_mapping = insert_embeddings_into_faiss(bert_embeddings, faiss_index)\n",
    "print(\"Inserted\", len(trace_mapping), \"traces into FAISS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03c83a6-2b77-4d80-a26d-90296485234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping saved successfully!\n"
     ]
    }
   ],
   "source": [
    "save_embeddings('../semantic_data/' + data + '/trace_mapping_vd.pkl', trace_mapping)\n",
    "print(\"Mapping saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5324f93-37b7-4d59-b0c8-a1025ef4ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def save_faiss_index(index, file_path):\n",
    "    \"\"\"\n",
    "    Saves a FAISS index to a file.\n",
    "\n",
    "    Args:\n",
    "        index (faiss.Index): The FAISS index to save.\n",
    "        file_path (str): Path to save the index.\n",
    "    \"\"\"\n",
    "    faiss.write_index(index, file_path)\n",
    "\n",
    "save_faiss_index(faiss_index, '../semantic_data/' + data + '/trace_faiss.index')\n",
    "print(\"FAISS index saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d9deea-415c-45a3-aebd-225cc893c61f",
   "metadata": {},
   "source": [
    "**Zero padding encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "560303cc-5c2f-418e-a61e-3a82a1756a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd969a0e-f1d1-4428-b35e-a2c6ada2ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stored traces\n",
    "def load_traces(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        distinct_traces = pickle.load(f)\n",
    "    return distinct_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e05854d-c5ed-4360-a190-ae4074e85c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded traces: [((0, 7, 5, 3, 24, 0, 8, 5, 0, 7, 5, 0, 25, 9, 7, 8, 10, 5, 5, 12, 0, 17, 5, 12, 27, 7, 5, 10, 0, 4, 5, 5, 35, 8, 1, 6, 13, 14, 5, 0, 4, 7, 3, 24, 26, 5, 33, 5, 11, 10, 5, 12, 13, 14, 13, 5, 14, 15, 16, 0, 19, 5, 20, 21, 5, 0, 30, 26, 4, 5, 27, 12, 5, 34, 24, 2, 3, 0, 26, 17, 18, 9, 7, 10, 19, 20, 5, 31, 19, 5, 20, 5, 5, 21, 23), 0.191516813160229), ((0, 17, 5, 0, 25, 5, 12, 5, 7, 26, 4, 5, 0, 25, 28, 5, 7, 10, 0, 7, 5, 4, 26, 5, 0, 10, 1, 26, 5, 3, 5, 13, 24, 14, 0, 3, 6, 35, 8, 5, 27, 26, 5, 34, 5, 0, 6, 5, 25, 4, 3, 26, 5, 13, 14, 5, 13, 14, 16, 0, 8, 17, 5, 5, 35, 6, 18, 19, 20, 22, 19, 20, 5, 31, 5, 0, 25, 5, 27, 7, 10, 5, 0, 8, 5, 12, 1, 3, 7, 5, 19, 20, 5, 31, 23), 0.191516813160229), ((0, 1, 0, 4, 5, 1, 5, 0, 3, 8, 6, 5, 5, 27, 1, 34, 5, 0, 6, 0, 1, 17, 5, 9, 10, 12, 5, 0, 4, 5, 35, 8, 12, 7, 1, 25, 28, 35, 6, 5, 13, 5, 14, 0, 5, 35, 6, 7, 13, 10, 12, 14, 5, 16, 0, 17, 12, 5, 7, 24, 5, 3, 10, 0, 1, 5, 8, 19, 35, 6, 5, 20, 21, 0, 5, 26, 5, 7, 27, 9, 10, 12, 0, 1, 9, 7, 10, 12, 19, 5, 20, 22, 5, 23, 36), 0.1895008467059108), ((0, 11, 0, 5, 0, 17, 27, 32, 34, 5, 7, 5, 10, 0, 1, 26, 33, 11, 5, 5, 6, 8, 5, 0, 10, 5, 6, 13, 8, 14, 5, 15, 0, 5, 7, 5, 32, 33, 11, 4, 26, 0, 12, 10, 5, 4, 26, 25, 3, 24, 7, 8, 5, 13, 5, 5, 14, 13, 14, 15, 16, 0, 0, 8, 0, 7, 28, 5, 25, 6, 8, 1, 3, 5, 19, 5, 20, 21, 0, 17, 7, 19, 5, 10, 5, 20, 22, 19, 20, 5, 22, 23, 36, 36, 36), 0.18546891379727443), ((0, 5, 4, 12, 7, 10, 5, 0, 4, 35, 8, 5, 5, 35, 6, 9, 7, 10, 12, 5, 0, 25, 12, 5, 3, 10, 5, 2, 24, 5, 0, 6, 17, 5, 27, 18, 0, 1, 8, 3, 24, 6, 10, 5, 12, 5, 5, 5, 30, 29, 5, 13, 14, 13, 14, 15, 13, 14, 16, 0, 17, 26, 5, 4, 5, 19, 20, 31, 0, 33, 5, 1, 19, 5, 20, 31, 5, 0, 7, 5, 0, 5, 30, 27, 34, 6, 5, 19, 20, 22, 23, 36, 36, 36, 36), 0.18345294734295622)]\n"
     ]
    }
   ],
   "source": [
    "data = \"mip\"\n",
    "trace_frequencies = load_traces('../semantic_data/' + data + '/' + data + '_encoded_trace_frequencies_all.pkl')\n",
    "print(\"Loaded traces:\", list(trace_data.items())[:5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f540ad5d-e730-4c79-8a19-1898df4eea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(trace) for trace in trace_frequencies.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6294676e-b84f-4be2-b20a-057345d82f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_trace(trace, max_length):\n",
    "    \"\"\"Converts a trace into a fixed-length vector using zero-padding.\"\"\"\n",
    "    vector = np.zeros(max_length, dtype=np.float32)\n",
    "    vector[:len(trace)] = trace  # Fill available positions with trace values\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fefa2d-9404-406e-b7ec-d8df1dd4bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and metadata saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index\n",
    "dimension = max_length\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 (Euclidean) distance index\n",
    "trace_list = []  # Stores original traces\n",
    "trace_freq_list = []  # Stores corresponding frequencies\n",
    "\n",
    "# Add traces to FAISS index\n",
    "for trace, freq in trace_frequencies.items():\n",
    "    trace_embedding = encode_trace(trace, max_length)\n",
    "    index.add(np.array([trace_embedding]))  # Add to FAISS index\n",
    "    trace_list.append(trace)  # Keep track of original traces\n",
    "    trace_freq_list.append(freq)\n",
    "\n",
    "# Save FAISS index and metadata\n",
    "faiss.write_index(index, '../semantic_data/' + data + '/faiss_0pad_index.bin')\n",
    "with open('../semantic_data/' + data + '/trace_metadata.pkl', \"wb\") as f:\n",
    "    pickle.dump({\"trace_list\": trace_list, \"trace_freq_list\": trace_freq_list, \"max_length\": max_length}, f)\n",
    "\n",
    "print(\"FAISS index and metadata saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab3890-1dc6-4e21-b76f-e239bdcc3a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
