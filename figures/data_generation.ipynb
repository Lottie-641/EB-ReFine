{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e99e29-3ee8-47f5-aec6-ebb05a5170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.objects.conversion.bpmn import converter as bpmn_converter\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as petri_simulator\n",
    "from pm4py.objects.log.obj import EventLog, Trace, Event\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.log.util import dataframe_utils\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c57e6ecb-d936-43ed-b6cc-75129474f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gdown --fuzzy \"https://drive.google.com/file/d/1v-ltQdytbyEOqlmKj9b61rPvHtRHQB6E/view?usp=sharing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c443f23-4343-4733-ae72-b5f0923f55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pm4py==2.2.27\n",
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72d4c7ce-6e43-4cba-a494-08328c076ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timestamp(log, start_time=None, hours_between=1):\n",
    "    \"\"\"\n",
    "    Flattens a PM4Py simulated event log into a list of dicts with columns: case, activity, timestamp.\n",
    "\n",
    "    Parameters:\n",
    "        simulated_log (pm4py.objects.log.obj.EventLog): The event log from simulation.\n",
    "        start_time (datetime): Optional start time for each trace (default: Jan 1, 2024, 8:00am).\n",
    "        hours_between (int): Hours of delay between events in a trace.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: Flattened event log.\n",
    "    \"\"\"\n",
    "    if start_time is None:\n",
    "        start_time = datetime(2024, 1, 1, 8, 0, 0)\n",
    "\n",
    "    flat_log = []\n",
    "    case_id = 1\n",
    "\n",
    "    for trace in simulated_log:\n",
    "        timestamp = start_time\n",
    "        for event in trace:\n",
    "            flat_log.append({\n",
    "                \"case\": case_id,\n",
    "                \"activity\": event[\"concept:name\"],\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            timestamp += timedelta(hours=hours_between)\n",
    "        case_id += 1\n",
    "\n",
    "    return flat_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16da60cc-d825-441d-9988-3f0dfdce9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trace_variants(df, case_col=\"case\", activity_col=\"activity\"):\n",
    "    \"\"\"\n",
    "    Counts the frequency of each unique trace variant in a flat event log DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The event log DataFrame with at least 'case' and 'activity' columns.\n",
    "        case_col (str): Name of the column representing case ID (default: 'case').\n",
    "        activity_col (str): Name of the column representing activity name (default: 'activity').\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object where keys are activity tuples (variants) and values are counts.\n",
    "    \"\"\"\n",
    "    trace_groups = df.groupby(case_col)[activity_col].apply(tuple)\n",
    "    variant_counts = Counter(trace_groups)\n",
    "    \n",
    "    print(\"ðŸ“Š Trace Variant Frequencies:\")\n",
    "    # for variant, count in variant_counts.items():\n",
    "    #     print(f\"{variant}: {count}\")\n",
    "    \n",
    "    return variant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beaea01c-b2d8-4466-a8af-2b9043d912a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Load BPMN file ---\n",
    "bpmn_path = \"wastewater_process_model_wo_circle_opt.bpmn\" \n",
    "bpmn_graph = bpmn_importer.apply(bpmn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f44377-0064-4684-98cb-c1cce0ec023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Convert BPMN to Petri net ---\n",
    "net, im, fm = bpmn_converter.apply(bpmn_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42359174-4138-4d59-9d3d-ff2a8734b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Simulate traces from Petri net ---\n",
    "simulated_log = petri_simulator.apply(net, im, parameters={\"no_traces\": 1200})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced68130-71cf-4cb0-8b9d-01a4c3d21877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Trace Variant Frequencies:\n",
      "Counter({('Coarse Screens', 'Fine Screens', 'Compacted Screenings', 'Disposal to Landfill'): 498, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Sludge Grinder', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 128, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Sludge Grinder', 'Blend Tank', 'Anaerobic Digester'): 121, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Final Clarifier', 'Chlorine Contact Basin', 'Pond', 'De-chlorination Pond', 'Cascade Aerator'): 71, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Final Clarifier', 'Chlorine Contact Basin', 'Pond', 'De-chlorination Pond', 'Effluent Pumping Station'): 58, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Wastewater Centrifuge De-watering Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 26, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Dissolved-Air Flotation Thickening', 'Blend Tank', 'Anaerobic Digester'): 24, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Gravity Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 21, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Wastewater Centrifuge De-watering Thickening', 'Blend Tank', 'Anaerobic Digester'): 20, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Gravity Thickening', 'Blend Tank', 'Anaerobic Digester'): 19, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Dissolved-Air Flotation Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 14})\n"
     ]
    }
   ],
   "source": [
    "flat_log = []\n",
    "case_id = 1\n",
    "log = create_timestamp(simulated_log, start_time=None, hours_between=1)\n",
    "\n",
    "df_log = pd.DataFrame(log)\n",
    "log_variant_counts = count_trace_variants(df_log)\n",
    "print(log_variant_counts)\n",
    "df_log.to_csv(\"original_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5764380-c801-45d1-89e2-a2f8960a75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_dict = defaultdict(list)\n",
    "for trace in simulated_log:\n",
    "    variant = tuple(event[\"concept:name\"] for event in trace)\n",
    "    variant_dict[variant].append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e528f0-6cde-42b1-9512-314f9f5ca706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set fixed number of traces per variant ---\n",
    "traces_per_variant = 91  # exact number per variant\n",
    "final_log = []\n",
    "case_id = 1\n",
    "\n",
    "for variant, traces in variant_dict.items():\n",
    "    # If we have fewer than needed, replicate traces to meet the target\n",
    "    full_traces = []\n",
    "    while len(full_traces) < traces_per_variant:\n",
    "        for t in traces:\n",
    "            full_traces.append(t)\n",
    "            if len(full_traces) == traces_per_variant:\n",
    "                break\n",
    "    for trace in full_traces:\n",
    "        timestamp = datetime(2024, 1, 1, 8, 0, 0)\n",
    "        for event in trace:\n",
    "            final_log.append({\n",
    "                \"case\": case_id,\n",
    "                \"activity\": event[\"concept:name\"],\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            timestamp += timedelta(hours=1)\n",
    "        case_id += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd0b3a5e-0074-478e-95d8-af7407b24a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Trace Variant Frequencies:\n",
      "Counter({('Coarse Screens', 'Fine Screens', 'Compacted Screenings', 'Disposal to Landfill'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Sludge Grinder', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Final Clarifier', 'Chlorine Contact Basin', 'Pond', 'De-chlorination Pond', 'Cascade Aerator'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Wastewater Centrifuge De-watering Thickening', 'Blend Tank', 'Anaerobic Digester'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Final Clarifier', 'Chlorine Contact Basin', 'Pond', 'De-chlorination Pond', 'Effluent Pumping Station'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Sludge Grinder', 'Blend Tank', 'Anaerobic Digester'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Gravity Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Gravity Thickening', 'Blend Tank', 'Anaerobic Digester'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Wastewater Centrifuge De-watering Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Dissolved-Air Flotation Thickening', 'Blend Tank', 'Anaerobic Digester'): 100, ('Coarse Screens', 'Fine Screens', 'Primary Clarifiers', 'Bio-reactor Tanks', 'Dissolved-Air Flotation Thickening', 'Blend Tank', 'Anaerobic Digester', 'Storage Tank', 'Disposal to Landfill'): 100})\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(final_log)\n",
    "final_log_variant_counts = count_trace_variants(df_final)\n",
    "print(final_log_variant_counts)\n",
    "df_final.to_csv(\"even_variant_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda8b8e-68c9-415e-aa55-5bd0a524e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e459c107-1946-46f3-99a0-955e9b3c51e1",
   "metadata": {},
   "source": [
    "## Filter out from the generated dataset by PLG with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05326e80-28a3-48fb-85f2-424efb2a8e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved 35545 events from 5370 evenly replicated traces.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "df = pd.read_csv(\"../event_log/wastewater/log_5000_all_noise_30.csv\")  \n",
    "\n",
    "grouped = df.groupby(\"case\")[\"activity\"].apply(tuple)\n",
    "\n",
    "variant_dict = defaultdict(list)\n",
    "for case_id, variant in grouped.items():\n",
    "    trace_df = df[df[\"case\"] == case_id]\n",
    "    trace_events = list(trace_df.sort_values(\"timestamp\").to_dict(\"records\"))\n",
    "    variant_dict[variant].append(trace_events)\n",
    "\n",
    "traces_per_variant = 5\n",
    "final_log = []\n",
    "new_case_id = 1\n",
    "\n",
    "for variant, traces in variant_dict.items():\n",
    "    full_traces = []\n",
    "    while len(full_traces) < traces_per_variant:\n",
    "        for t in traces:\n",
    "            full_traces.append(t)\n",
    "            if len(full_traces) == traces_per_variant:\n",
    "                break\n",
    "\n",
    "    for trace in full_traces:\n",
    "        timestamp = datetime(2024, 1, 1, 8, 0, 0)\n",
    "        for event in trace:\n",
    "            final_log.append({\n",
    "                \"case\": new_case_id,\n",
    "                \"activity\": event[\"activity\"],\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "            timestamp += timedelta(hours=1)\n",
    "        new_case_id += 1\n",
    "\n",
    "final_df = pd.DataFrame(final_log)\n",
    "final_df.to_csv(\"replicated_even_variant_log.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Saved {len(final_df)} events from {new_case_id - 1} evenly replicated traces.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066d1cf-aa67-4a4c-a1d8-051071f0ba1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
